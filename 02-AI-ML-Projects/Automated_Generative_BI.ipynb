{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Yr7iabEgYLu"
      },
      "outputs": [],
      "source": [
        "# Use -q for a \"quiet\" installation to keep the output clean\n",
        "!pip install -q pandas gspread google-auth-oauthlib google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# IMPORTANT: Fill in your Google Cloud Project ID here\n",
        "GCP_PROJECT_ID = \"smartbi-digest\"\n",
        "GCP_LOCATION = \"us-east4\"\n",
        "\n",
        "# --- AUTHENTICATION ---\n",
        "# This will trigger a pop-up to ask for your permission.\n",
        "print(\"Authenticating to Google...\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "# --- INITIALIZE CLIENTS ---\n",
        "print(\"Initializing clients for Google Sheets and Vertex AI...\")\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "vertexai.init(project=GCP_PROJECT_ID, location=GCP_LOCATION, credentials=creds)\n",
        "\n",
        "print(\"\\nâœ… Setup Complete! You are now authenticated and ready to proceed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvdH-B6TgZYS",
        "outputId": "910ff0da-590c-457a-d2de-f966af5c12fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticating to Google...\n",
            "Initializing clients for Google Sheets and Vertex AI...\n",
            "\n",
            "âœ… Setup Complete! You are now authenticated and ready to proceed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "# IMPORTANT: Fill in the exact names from your Google Sheets\n",
        "SPREADSHEET_NAME = \"Credit Card Data\"  # <-- e.g., \"Daily Monetization Report\"\n",
        "WORKSHEET_NAME = \"credit_card_data\"                         # <-- e.g., \"Data Tab\" or \"Report View\"\n",
        "\n",
        "# --- DATA LOADING & EDA ---\n",
        "eda_summary = \"\"\n",
        "try:\n",
        "    print(f\"ðŸ”„ Opening Google Sheet: '{SPREADSHEET_NAME}'...\")\n",
        "    spreadsheet = gc.open(SPREADSHEET_NAME)\n",
        "\n",
        "    print(f\"ðŸ”„ Accessing worksheet: '{WORKSHEET_NAME}'...\")\n",
        "    worksheet = spreadsheet.worksheet(WORKSHEET_NAME)\n",
        "\n",
        "    print(\"â³ Loading all data into a DataFrame... (This may take a moment for large sheets)\")\n",
        "    data = worksheet.get_all_records()\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"âš ï¸ Warning: The worksheet is empty or could not be read properly.\")\n",
        "    else:\n",
        "        print(\"âœ… Data loaded successfully!\")\n",
        "\n",
        "        print(\"\\nðŸ”¬ Performing Exploratory Data Analysis...\")\n",
        "        # 1. Get the shape of the data\n",
        "        shape = f\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\\n\"\n",
        "\n",
        "        # 2. Get the column names\n",
        "        columns = f\"Columns: {', '.join(df.columns)}\\n\"\n",
        "\n",
        "        # 3. Get the numerical summary\n",
        "        # We need to handle cases where there are no numeric columns\n",
        "        numeric_cols = df.select_dtypes(include='number')\n",
        "        if not numeric_cols.empty:\n",
        "            numerical_summary = \"Numerical Summary:\\n\" + numeric_cols.describe().to_string()\n",
        "        else:\n",
        "            numerical_summary = \"Numerical Summary: No numerical columns found in the data.\"\n",
        "\n",
        "        # 4. Consolidate into a single summary string\n",
        "        eda_summary = shape + columns + \"\\n\" + numerical_summary\n",
        "\n",
        "        print(\"\\n--- Full Data EDA Summary ---\")\n",
        "        print(eda_summary)\n",
        "        print(\"--- End of Summary ---\")\n",
        "\n",
        "except gspread.exceptions.SpreadsheetNotFound:\n",
        "    print(f\"âŒ ERROR: Spreadsheet '{SPREADSHEET_NAME}' not found. Please check the name and ensure you have access.\")\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    print(f\"âŒ ERROR: Worksheet '{WORKSHEET_NAME}' not found in the spreadsheet. Please check the tab name.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvNTDpC3gdmD",
        "outputId": "a1b713d5-d7e0-4ba9-c7f8-624de70109e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Opening Google Sheet: 'Credit Card Data'...\n",
            "ðŸ”„ Accessing worksheet: 'credit_card_data'...\n",
            "â³ Loading all data into a DataFrame... (This may take a moment for large sheets)\n",
            "âœ… Data loaded successfully!\n",
            "\n",
            "ðŸ”¬ Performing Exploratory Data Analysis...\n",
            "\n",
            "--- Full Data EDA Summary ---\n",
            "Dataset Shape: 8950 rows, 18 columns\n",
            "Columns: CUST_ID, BALANCE, BALANCE_FREQUENCY, PURCHASES, ONEOFF_PURCHASES, INSTALLMENTS_PURCHASES, CASH_ADVANCE, PURCHASES_FREQUENCY, ONEOFF_PURCHASES_FREQUENCY, PURCHASES_INSTALLMENTS_FREQUENCY, CASH_ADVANCE_FREQUENCY, CASH_ADVANCE_TRX, PURCHASES_TRX, CREDIT_LIMIT, PAYMENTS, MINIMUM_PAYMENTS, PRC_FULL_PAYMENT, TENURE\n",
            "\n",
            "Numerical Summary:\n",
            "            BALANCE  BALANCE_FREQUENCY     PURCHASES  ONEOFF_PURCHASES  INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX      PAYMENTS  PRC_FULL_PAYMENT       TENURE\n",
            "count   8950.000000        8950.000000   8950.000000       8950.000000             8950.000000   8950.000000          8950.000000                 8950.000000                       8950.000000             8950.000000       8950.000000    8950.000000   8950.000000       8950.000000  8950.000000\n",
            "mean    1564.474828           0.877271   1003.204834        592.437371              411.067645    978.871112             0.490351                    0.202458                          0.364437                0.135144          3.248827      14.709832   1733.143852          0.153715    11.517318\n",
            "std     2081.531879           0.236904   2136.634782       1659.887917              904.338115   2097.163877             0.401371                    0.298336                          0.397448                0.200121          6.824647      24.857649   2895.063757          0.292499     1.338331\n",
            "min        0.000000           0.000000      0.000000          0.000000                0.000000      0.000000             0.000000                    0.000000                          0.000000                0.000000          0.000000       0.000000      0.000000          0.000000     6.000000\n",
            "25%      128.281915           0.888889     39.635000          0.000000                0.000000      0.000000             0.083333                    0.000000                          0.000000                0.000000          0.000000       1.000000    383.276166          0.000000    12.000000\n",
            "50%      873.385231           1.000000    361.280000         38.000000               89.000000      0.000000             0.500000                    0.083333                          0.166667                0.000000          0.000000       7.000000    856.901546          0.000000    12.000000\n",
            "75%     2054.140036           1.000000   1110.130000        577.405000              468.637500   1113.821139             0.916667                    0.300000                          0.750000                0.222222          4.000000      17.000000   1901.134317          0.142857    12.000000\n",
            "max    19043.138560           1.000000  49039.570000      40761.250000            22500.000000  47137.211760             1.000000                    1.000000                          1.000000                1.500000        123.000000     358.000000  50721.483360          1.000000    12.000000\n",
            "--- End of Summary ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# --- CALL GEMINI API ---\n",
        "\n",
        "# Check if the EDA summary was generated successfully before proceeding\n",
        "if 'eda_summary' in locals() and eda_summary:\n",
        "    print(\"ðŸ§  Preparing prompt and calling Gemini API... This may take a few seconds.\")\n",
        "\n",
        "    try:\n",
        "        # Initialize the specific model we want to use\n",
        "        # gemini-1.5-flash is fast, multi-modal, has a large context window and is cost-effective.\n",
        "        model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "\n",
        "        # This is our powerful \"meta-prompt\" that instructs the AI\n",
        "        prompt = f\"\"\"\n",
        "        You are a world-class principal data analyst at a major telecommunications company.\n",
        "        Your task is to interpret the following Exploratory Data Analysis (EDA) summary of a full dataset and generate\n",
        "        5 insightful, actionable questions that a business director should investigate next.\n",
        "\n",
        "        The questions should be sharp, data-driven, and directly inspired by the statistical facts presented.\n",
        "\n",
        "        --- Full Dataset EDA Summary ---\n",
        "        {eda_summary}\n",
        "        --- End of Summary ---\n",
        "\n",
        "        Based ONLY on this statistical summary, generate a JSON object containing a single key \"questions\" which holds a list of 5 string questions.\n",
        "        Example Format: {{\"questions\": [\"question 1\", \"question 2\", ...]}}\n",
        "        \"\"\"\n",
        "\n",
        "        # Call the model\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        # --- PARSE AND DISPLAY RESULTS ---\n",
        "        print(\"\\nðŸŽ‰ Success! Here are the AI-generated questions:\\n\")\n",
        "\n",
        "        # Attempt to parse the JSON response for clean formatting\n",
        "        try:\n",
        "            # The model might return the JSON wrapped in markdown, so we clean it\n",
        "            cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "            data = json.loads(cleaned_response)\n",
        "\n",
        "            # Print as a numbered list\n",
        "            for i, question in enumerate(data['questions'], 1):\n",
        "                print(f\"{i}. {question}\\n\")\n",
        "\n",
        "        except (json.JSONDecodeError, KeyError) as e:\n",
        "            print(\"Could not parse JSON, displaying raw text instead:\\n\")\n",
        "            print(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ An error occurred while calling the Gemini API: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ EDA summary not found. Please run the previous cell successfully before running this one.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izZR1g_0hSve",
        "outputId": "1d74ee0f-067a-4dcf-93f5-5d1f84fbf65d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Preparing prompt and calling Gemini API... This may take a few seconds.\n",
            "\n",
            "ðŸŽ‰ Success! Here are the AI-generated questions:\n",
            "\n",
            "1. Given the large standard deviation of 'BALANCE' and 'CASH_ADVANCE', and the high maximum values, what strategies can we implement to mitigate risk associated with high balances and cash advances, and are there any credit limit adjustments needed?\n",
            "\n",
            "2. The mean 'PURCHASES_FREQUENCY' is only 0.49, and the mean 'ONEOFF_PURCHASES_FREQUENCY' is 0.20, suggesting a substantial portion of customers are not making purchases frequently. What marketing or incentive programs can we develop to encourage higher purchase frequency, particularly for one-off purchases?\n",
            "\n",
            "3. The mean 'PRC_FULL_PAYMENT' is 0.15, indicating most customers do not pay their balance in full. How does this impact profitability, and what payment plans or features can we offer to encourage customers to pay in full more often?\n",
            "\n",
            "4. Although the average tenure is 11.5 months with a range from 6 to 12 months, there's a substantial spread in 'BALANCE' across the customers. Are there any significant differences in the credit usage (balance, purchases, cash advances) and payment behaviour of customers with different tenures that require specialized strategies? \n",
            "\n",
            "5. With a large difference between the mean and max values for  'ONEOFF_PURCHASES' and 'INSTALLMENTS_PURCHASES', can we segment the customers by the way they spend money.  What are the characteristics of customers who prefer 'ONEOFF_PURCHASES' and 'INSTALLMENTS_PURCHASES' and can we tailor marketing efforts to those spending habits?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXcicBZihbqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}